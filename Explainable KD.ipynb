{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb76e64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:17.154525Z",
     "iopub.status.busy": "2024-05-02T17:43:17.154130Z",
     "iopub.status.idle": "2024-05-02T17:43:18.080623Z",
     "shell.execute_reply": "2024-05-02T17:43:18.079523Z"
    },
    "papermill": {
     "duration": 0.938467,
     "end_time": "2024-05-02T17:43:18.083507",
     "exception": false,
     "start_time": "2024-05-02T17:43:17.145040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc00a87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:18.099703Z",
     "iopub.status.busy": "2024-05-02T17:43:18.099138Z",
     "iopub.status.idle": "2024-05-02T17:43:18.104212Z",
     "shell.execute_reply": "2024-05-02T17:43:18.103130Z"
    },
    "papermill": {
     "duration": 0.015822,
     "end_time": "2024-05-02T17:43:18.106743",
     "exception": false,
     "start_time": "2024-05-02T17:43:18.090921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAIN_DIR = '/kaggle/input/pascal-voc-2012/VOC2012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29adc4c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:18.121748Z",
     "iopub.status.busy": "2024-05-02T17:43:18.121315Z",
     "iopub.status.idle": "2024-05-02T17:43:18.134061Z",
     "shell.execute_reply": "2024-05-02T17:43:18.132718Z"
    },
    "papermill": {
     "duration": 0.023517,
     "end_time": "2024-05-02T17:43:18.136777",
     "exception": false,
     "start_time": "2024-05-02T17:43:18.113260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xml_to_csv(path = os.path.join(MAIN_DIR,'Annotations')):\n",
    "    xml_list = []\n",
    "    \n",
    "    for xml_file in tqdm(glob.glob(os.path.join(path, '2007*.xml'))):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        for obj in root.findall('object'):\n",
    "            bbx = obj.find('bndbox')\n",
    "            xmin = int(bbx.find('xmin').text)\n",
    "            ymin = int(bbx.find('ymin').text)\n",
    "            xmax = int(bbx.find('xmax').text)\n",
    "            ymax = int(bbx.find('ymax').text)\n",
    "            label = obj.find('name').text\n",
    "\n",
    "            # it would be better to use column name instead of index\n",
    "            value = (root.find('filename').text,\n",
    "                     int(root.find('size').find('depth').text), #0 , 2\n",
    "                     int(root.find('size').find('width').text), #1 , 0\n",
    "                     int(root.find('size').find('height').text), #2 , 1\n",
    "                     label,\n",
    "                     xmin,\n",
    "                     ymin,\n",
    "                     xmax,\n",
    "                     ymax\n",
    "                     )\n",
    "            xml_list.append(value)\n",
    "            \n",
    "    column_name = ['filename', 'channels', 'width', 'height',\n",
    "                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    \n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    \n",
    "    return xml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515b1159",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:18.151944Z",
     "iopub.status.busy": "2024-05-02T17:43:18.150950Z",
     "iopub.status.idle": "2024-05-02T17:43:24.753281Z",
     "shell.execute_reply": "2024-05-02T17:43:24.752205Z"
    },
    "papermill": {
     "duration": 6.613063,
     "end_time": "2024-05-02T17:43:24.756283",
     "exception": false,
     "start_time": "2024-05-02T17:43:18.143220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 756/756 [00:05<00:00, 128.28it/s]\n"
     ]
    }
   ],
   "source": [
    "xml_df = xml_to_csv().head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74233378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:24.782720Z",
     "iopub.status.busy": "2024-05-02T17:43:24.781617Z",
     "iopub.status.idle": "2024-05-02T17:43:24.795819Z",
     "shell.execute_reply": "2024-05-02T17:43:24.794903Z"
    },
    "papermill": {
     "duration": 0.030055,
     "end_time": "2024-05-02T17:43:24.798447",
     "exception": false,
     "start_time": "2024-05-02T17:43:24.768392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xml_df.to_csv('data_descriptor.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c74e65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:24.823813Z",
     "iopub.status.busy": "2024-05-02T17:43:24.823410Z",
     "iopub.status.idle": "2024-05-02T17:43:24.854258Z",
     "shell.execute_reply": "2024-05-02T17:43:24.853121Z"
    },
    "papermill": {
     "duration": 0.046028,
     "end_time": "2024-05-02T17:43:24.856740",
     "exception": false,
     "start_time": "2024-05-02T17:43:24.810712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>channels</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007_005144.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>332</td>\n",
       "      <td>500</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>331</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007_005989.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>375</td>\n",
       "      <td>motorbike</td>\n",
       "      <td>140</td>\n",
       "      <td>130</td>\n",
       "      <td>408</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007_005989.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>375</td>\n",
       "      <td>person</td>\n",
       "      <td>213</td>\n",
       "      <td>96</td>\n",
       "      <td>355</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007_002107.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>375</td>\n",
       "      <td>aeroplane</td>\n",
       "      <td>408</td>\n",
       "      <td>243</td>\n",
       "      <td>449</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007_000822.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>374</td>\n",
       "      <td>motorbike</td>\n",
       "      <td>98</td>\n",
       "      <td>165</td>\n",
       "      <td>230</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2007_004663.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>375</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>407</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2007_003571.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>333</td>\n",
       "      <td>boat</td>\n",
       "      <td>259</td>\n",
       "      <td>206</td>\n",
       "      <td>500</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2007_005428.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>bottle</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>217</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2007_007414.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>333</td>\n",
       "      <td>person</td>\n",
       "      <td>453</td>\n",
       "      <td>50</td>\n",
       "      <td>491</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2007_007414.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>333</td>\n",
       "      <td>car</td>\n",
       "      <td>187</td>\n",
       "      <td>107</td>\n",
       "      <td>386</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  channels  width  height      class  xmin  ymin  xmax  \\\n",
       "0    2007_005144.jpg         3    332     500     person     1    12   331   \n",
       "1    2007_005989.jpg         3    500     375  motorbike   140   130   408   \n",
       "2    2007_005989.jpg         3    500     375     person   213    96   355   \n",
       "3    2007_002107.jpg         3    500     375  aeroplane   408   243   449   \n",
       "4    2007_000822.jpg         3    500     374  motorbike    98   165   230   \n",
       "..               ...       ...    ...     ...        ...   ...   ...   ...   \n",
       "495  2007_004663.jpg         3    500     375      train     1   168   407   \n",
       "496  2007_003571.jpg         3    500     333       boat   259   206   500   \n",
       "497  2007_005428.jpg         3    375     500     bottle     1     1   217   \n",
       "498  2007_007414.jpg         3    500     333     person   453    50   491   \n",
       "499  2007_007414.jpg         3    500     333        car   187   107   386   \n",
       "\n",
       "     ymax  \n",
       "0     500  \n",
       "1     273  \n",
       "2     260  \n",
       "3     257  \n",
       "4     346  \n",
       "..    ...  \n",
       "495   260  \n",
       "496   333  \n",
       "497   362  \n",
       "498   110  \n",
       "499   196  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5cb35c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:24.882667Z",
     "iopub.status.busy": "2024-05-02T17:43:24.882218Z",
     "iopub.status.idle": "2024-05-02T17:43:24.888366Z",
     "shell.execute_reply": "2024-05-02T17:43:24.887306Z"
    },
    "papermill": {
     "duration": 0.02199,
     "end_time": "2024-05-02T17:43:24.890806",
     "exception": false,
     "start_time": "2024-05-02T17:43:24.868816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \n",
    "           \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\",\n",
    "           \"train\", \"tvmonitor\"]\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4001fe34",
   "metadata": {
    "papermill": {
     "duration": 0.01179,
     "end_time": "2024-05-02T17:43:24.914578",
     "exception": false,
     "start_time": "2024-05-02T17:43:24.902788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Vanilla KD Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d9dcd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:24.942598Z",
     "iopub.status.busy": "2024-05-02T17:43:24.941619Z",
     "iopub.status.idle": "2024-05-02T17:43:33.233410Z",
     "shell.execute_reply": "2024-05-02T17:43:33.232344Z"
    },
    "papermill": {
     "duration": 8.308339,
     "end_time": "2024-05-02T17:43:33.236226",
     "exception": false,
     "start_time": "2024-05-02T17:43:24.927887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf1a30b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:33.263556Z",
     "iopub.status.busy": "2024-05-02T17:43:33.262983Z",
     "iopub.status.idle": "2024-05-02T17:43:33.271793Z",
     "shell.execute_reply": "2024-05-02T17:43:33.270525Z"
    },
    "papermill": {
     "duration": 0.025313,
     "end_time": "2024-05-02T17:43:33.274687",
     "exception": false,
     "start_time": "2024-05-02T17:43:33.249374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(MAIN_DIR,'JPEGImages',self.dataframe.iloc[idx]['filename'])\n",
    "        label = self.dataframe.iloc[idx]['class']\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c152060e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:33.301959Z",
     "iopub.status.busy": "2024-05-02T17:43:33.301168Z",
     "iopub.status.idle": "2024-05-02T17:43:33.309329Z",
     "shell.execute_reply": "2024-05-02T17:43:33.308141Z"
    },
    "papermill": {
     "duration": 0.024306,
     "end_time": "2024-05-02T17:43:33.311819",
     "exception": false,
     "start_time": "2024-05-02T17:43:33.287513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(xml_df['class'])\n",
    "xml_df['class'] = label_encoder.transform(xml_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f62b8b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:33.340428Z",
     "iopub.status.busy": "2024-05-02T17:43:33.339318Z",
     "iopub.status.idle": "2024-05-02T17:43:33.350896Z",
     "shell.execute_reply": "2024-05-02T17:43:33.349606Z"
    },
    "papermill": {
     "duration": 0.029013,
     "end_time": "2024-05-02T17:43:33.354000",
     "exception": false,
     "start_time": "2024-05-02T17:43:33.324987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Assuming using ImageNet normalization\n",
    "])\n",
    "\n",
    "dataset = CustomDataset(xml_df, transform = transform)\n",
    "dataloader = DataLoader(dataset, batch_size = 1, shuffle=True, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d32b462b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:33.382658Z",
     "iopub.status.busy": "2024-05-02T17:43:33.381545Z",
     "iopub.status.idle": "2024-05-02T17:43:33.879384Z",
     "shell.execute_reply": "2024-05-02T17:43:33.878082Z"
    },
    "papermill": {
     "duration": 0.515261,
     "end_time": "2024-05-02T17:43:33.882483",
     "exception": false,
     "start_time": "2024-05-02T17:43:33.367222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 80.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "mobilenet.classifier[1] = torch.nn.Linear(mobilenet.classifier[1].in_features, num_classes)\n",
    "\n",
    "class ModifiedMobileNetV2(nn.Module):\n",
    "    def __init__(self, mobilenet):\n",
    "        super(ModifiedMobileNetV2, self).__init__()\n",
    "        self.mobilenet = mobilenet\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mobilenet(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "mobilenet = ModifiedMobileNetV2(mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "131ccabc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:33.911991Z",
     "iopub.status.busy": "2024-05-02T17:43:33.911558Z",
     "iopub.status.idle": "2024-05-02T17:43:33.919448Z",
     "shell.execute_reply": "2024-05-02T17:43:33.918117Z"
    },
    "papermill": {
     "duration": 0.025216,
     "end_time": "2024-05-02T17:43:33.922234",
     "exception": false,
     "start_time": "2024-05-02T17:43:33.897018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "kl_div_loss = nn.KLDivLoss()\n",
    "optimizer = optim.SGD(mobilenet.parameters(), lr=0.005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde8402a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:33.951724Z",
     "iopub.status.busy": "2024-05-02T17:43:33.950526Z",
     "iopub.status.idle": "2024-05-02T17:43:33.959309Z",
     "shell.execute_reply": "2024-05-02T17:43:33.957992Z"
    },
    "papermill": {
     "duration": 0.026463,
     "end_time": "2024-05-02T17:43:33.962065",
     "exception": false,
     "start_time": "2024-05-02T17:43:33.935602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModifiedResnet(nn.Module):\n",
    "    def __init__(self, resnet):\n",
    "        super(ModifiedResnet, self).__init__()\n",
    "        self.resnet = resnet\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38db1cd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:33.992691Z",
     "iopub.status.busy": "2024-05-02T17:43:33.992129Z",
     "iopub.status.idle": "2024-05-02T17:43:34.426951Z",
     "shell.execute_reply": "2024-05-02T17:43:34.425812Z"
    },
    "papermill": {
     "duration": 0.454156,
     "end_time": "2024-05-02T17:43:34.429739",
     "exception": false,
     "start_time": "2024-05-02T17:43:33.975583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher = pickle.load(open('/kaggle/input/deeplearning-data/teacher.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8f281be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:34.457944Z",
     "iopub.status.busy": "2024-05-02T17:43:34.457520Z",
     "iopub.status.idle": "2024-05-02T17:43:34.469781Z",
     "shell.execute_reply": "2024-05-02T17:43:34.468703Z"
    },
    "papermill": {
     "duration": 0.02917,
     "end_time": "2024-05-02T17:43:34.472171",
     "exception": false,
     "start_time": "2024-05-02T17:43:34.443001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_gradcam_map_resnet(model, input_image, target_class=None):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward pass\n",
    "    features = model.conv1(input_image)\n",
    "    features = model.bn1(features)\n",
    "    features = model.relu(features)\n",
    "    features = model.maxpool(features)\n",
    "\n",
    "    features = model.layer1(features)\n",
    "    features = model.layer2(features)\n",
    "    features = model.layer3(features)\n",
    "    features = model.layer4(features)\n",
    "\n",
    "    # Average pooling to reduce spatial dimensions to 1x1\n",
    "    pooled_features = nn.functional.adaptive_avg_pool2d(features, 1)\n",
    "    \n",
    "    # Compute the gradients of the target class score with respect to the pooled feature maps\n",
    "    gradients = None\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad_(True)\n",
    "    output = model.fc(pooled_features.view(pooled_features.size(0), -1))\n",
    "    if target_class is None:\n",
    "        target_class = output.argmax(dim=1)\n",
    "    output[:, target_class].backward(retain_graph=True)\n",
    "    gradients = model.layer4[-1].conv2.weight.grad\n",
    "    alpha = gradients.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "    # Compute the importance weights for each feature map\n",
    "    gradcam_map = (alpha * features).sum(dim=1, keepdim=True)\n",
    "    gradcam_map = nn.functional.relu(gradcam_map)\n",
    "    \n",
    "    # Resize the Grad-CAM map to match the input size\n",
    "    gradcam_map = nn.functional.interpolate(gradcam_map, size=(10, 10), mode='bilinear', align_corners=False)\n",
    "\n",
    "    return torch.mean(gradcam_map, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1b0af38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:34.500360Z",
     "iopub.status.busy": "2024-05-02T17:43:34.499958Z",
     "iopub.status.idle": "2024-05-02T17:43:34.511879Z",
     "shell.execute_reply": "2024-05-02T17:43:34.510796Z"
    },
    "papermill": {
     "duration": 0.028882,
     "end_time": "2024-05-02T17:43:34.514384",
     "exception": false,
     "start_time": "2024-05-02T17:43:34.485502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_gradcam_map_mobilenet(model, input_image, target_class=None):\n",
    "    activation = {}\n",
    "    gradient = {}\n",
    "\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    def get_gradient(name):\n",
    "        def hook(module, grad_input, grad_output):\n",
    "            gradient[name] = grad_output[0].detach()\n",
    "        return hook\n",
    "\n",
    "    hook1 = model.features[-1].register_forward_hook(get_activation('features'))\n",
    "    hook2 = model.features[-1].register_backward_hook(get_gradient('features'))\n",
    "    \n",
    "    model.eval()\n",
    "    output = model(input_image)\n",
    "    target_class = torch.argmax(output)\n",
    "\n",
    "    model.zero_grad()\n",
    "    output[:, target_class].backward(create_graph=True)\n",
    "    grads = gradient['features']\n",
    "    activations = activation['features']\n",
    "\n",
    "    for i in range(activations.shape[0]):\n",
    "        activations[i, :] *= grads[i, :]\n",
    "    grad_cam = torch.mean(activations, dim=1).unsqueeze(0)\n",
    "\n",
    "    grad_cam = F.relu(grad_cam)\n",
    "    gradcam_map = nn.functional.interpolate(grad_cam, size=(10, 10), mode='bilinear', align_corners=False)\n",
    "    gradcam_map = gradcam_map.squeeze()\n",
    "    \n",
    "    hook1.remove()\n",
    "    hook2.remove()\n",
    "    return gradcam_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ead94c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:34.542669Z",
     "iopub.status.busy": "2024-05-02T17:43:34.542264Z",
     "iopub.status.idle": "2024-05-02T17:43:34.548958Z",
     "shell.execute_reply": "2024-05-02T17:43:34.547540Z"
    },
    "papermill": {
     "duration": 0.023537,
     "end_time": "2024-05-02T17:43:34.551418",
     "exception": false,
     "start_time": "2024-05-02T17:43:34.527881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_hooks(model):\n",
    "    for module in model.modules():\n",
    "        # Check if the module has any hooks\n",
    "        if hasattr(module, '_forward_hooks'):\n",
    "            # Remove all hooks from the module\n",
    "            module._forward_hooks.clear()\n",
    "        if hasattr(module, '_backward_hooks'):\n",
    "            module._backward_hooks.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06860c47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T17:43:34.580229Z",
     "iopub.status.busy": "2024-05-02T17:43:34.579442Z",
     "iopub.status.idle": "2024-05-02T19:06:53.303030Z",
     "shell.execute_reply": "2024-05-02T19:06:53.301680Z"
    },
    "papermill": {
     "duration": 4998.756297,
     "end_time": "2024-05-02T19:06:53.321183",
     "exception": false,
     "start_time": "2024-05-02T17:43:34.564886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ../torch/csrc/autograd/engine.cpp:1171.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 2.7387\n",
      "Epoch 2/15, Loss: 2.7326\n",
      "Epoch 3/15, Loss: 2.7320\n",
      "Epoch 4/15, Loss: 2.7311\n",
      "Epoch 5/15, Loss: 2.7304\n",
      "Epoch 6/15, Loss: 2.7298\n",
      "Epoch 7/15, Loss: 2.7299\n",
      "Epoch 8/15, Loss: 2.7294\n",
      "Epoch 9/15, Loss: 2.7292\n",
      "Epoch 10/15, Loss: 2.7304\n",
      "Epoch 11/15, Loss: 2.7327\n",
      "Epoch 12/15, Loss: 2.7368\n",
      "Epoch 13/15, Loss: 2.7428\n",
      "Epoch 14/15, Loss: 2.7443\n",
      "Epoch 15/15, Loss: 2.7323\n"
     ]
    }
   ],
   "source": [
    "def train_model(student_model, teacher_model, criterion, optimizer, num_epochs = 10):\n",
    "    for epoch in range(num_epochs):\n",
    "        student_model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)    \n",
    "            student_outputs = student_model(inputs)\n",
    "            \n",
    "            teacher_CAM = get_gradcam_map_resnet(teacher_model.resnet, inputs)\n",
    "            student_CAM = get_gradcam_map_mobilenet(student_model.mobilenet, inputs)\n",
    "            \n",
    "            teacher_model.zero_grad()\n",
    "            student_model.zero_grad()\n",
    "            \n",
    "            kd_loss = kl_div_loss(student_outputs, teacher_outputs)\n",
    "            ce_loss = criterion(student_outputs, labels)\n",
    "            \n",
    "            teacher_CAM = teacher_CAM.view(-1)\n",
    "            student_CAM = student_CAM.view(-1)\n",
    "            cosine_similarity = F.cosine_similarity(teacher_CAM, student_CAM, dim=0)\n",
    "            cosine_distance = 1 - cosine_similarity\n",
    "            \n",
    "            loss = kd_loss + ce_loss + cosine_distance\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader.dataset):.4f}\")\n",
    "        remove_hooks(student_model)\n",
    "        with open(f'mobilenet_EKD{epoch+1}.pkl', 'wb') as file:\n",
    "            pickle.dump(student_model, file)\n",
    "train_model(mobilenet, teacher, criterion, optimizer, num_epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb84f957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T19:06:53.354091Z",
     "iopub.status.busy": "2024-05-02T19:06:53.353655Z",
     "iopub.status.idle": "2024-05-02T19:06:53.405073Z",
     "shell.execute_reply": "2024-05-02T19:06:53.404052Z"
    },
    "papermill": {
     "duration": 0.071196,
     "end_time": "2024-05-02T19:06:53.407709",
     "exception": false,
     "start_time": "2024-05-02T19:06:53.336513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('mobilenet_EKD.pkl', 'wb') as file:\n",
    "    pickle.dump(mobilenet, file)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 35388,
     "sourceId": 47853,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4922257,
     "sourceId": 8290020,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5020.964196,
   "end_time": "2024-05-02T19:06:55.059602",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-02T17:43:14.095406",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
